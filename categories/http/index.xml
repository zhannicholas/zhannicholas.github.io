<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>HTTP on 's Digital Garden</title><link>https://zhannicholas.github.io/categories/http/</link><description>Recent content in HTTP on 's Digital Garden</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 13 Dec 2020 17:25:35 +0800</lastBuildDate><atom:link href="https://zhannicholas.github.io/categories/http/index.xml" rel="self" type="application/rss+xml"/><item><title>HTTP：URI与资源</title><link>https://zhannicholas.github.io/posts/computer_networks/http/uri_and_resources/</link><pubDate>Sun, 13 Dec 2020 17:25:35 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/uri_and_resources/</guid><description>Web资源 Web资源（Web resource），或资源（resource）是一个非常宽泛的概念，它代表一个可以被识别的东西。WikiPedia 是这么描述它的：
A web resource, or simply resource, is any identifiable thing, whether digital, physical, or abstract.
在早期的Web中，资源就是可寻址的静态文档（documents）或文件（files）。随着Web的发展，资源变得越来越宽泛和抽象，现在的资源包括一切可以被识别的东西或实体。
Web资源保存在Web服务器上，通过 统一资源标识符（Uniform Resource Identifier, URI） 进行识别。
URI A Uniform Resource Identifier (URI) is a string of characters that unambiguously identifies a particular resource.
RFC2396 对组成了URI的三个单词进行了定义：
Uniform: 规定统一的格式可方便处理多种不同类型的资源，而不用根据上下文 环境来识别资源指定的访问方式。另外，加入新增的协议方案（如 http: 或 ftp:）也更容易。 Resource: 资源的定义是“可标识的任何东西”。除了文档文件、图像或服务（例 如当天的天气预报）等能够区别于其他类型的，全都可作为资源。另 外，资源不仅可以是单一的，也可以是多数的集合体。 Identifier: 表示可标识的对象。也称为标识符。 简而言之，URI可以唯一标识并定位Web上的资源，它有URL和URN两种形式。
URI的语法 为了保证一致性（uniformity），所有的URI都遵循了一个预定义的规则集。虽然如此，URI也可以通过 命名方案（naming scheme） 进行扩展。
URI的通用语法定义如下，它由5部分组成：
URI = scheme:[//authority]path[?query][#fragment] authority = [userinfo@]host[:port] 上面的语法定义也可以用语法树来表示：</description></item><item><title>HTTP：代理</title><link>https://zhannicholas.github.io/posts/computer_networks/http/proxies/</link><pubDate>Sun, 13 Dec 2020 17:19:57 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/proxies/</guid><description>Web代理（Proxy） 服务器是网络中的中间实体，位于客户端与服务器之间，扮演的是“中间人”的角色，负责在各端点之间来回传送HTTP报文。
Web的中间实体 Web代理服务器是代表客户端完成事务处理的中间人。如果没有Web代理，HTTP客户端就要直接与服务器进行对话。而有了Web代理之后，客户端就可以与代理进行对话，然后代理代表客户端与服务器进行交流。客户端仍然可以完成事务处理，但代理可以为它带来更加优质的服务和更加灵活的扩展功能。
HTTP代理服务器既是Web客户端，又是Web服务器。对于客户端而言，Web代理扮演的是服务器的角色，它必须正确处理请求并进行响应。同时，对于服务器而言，Web代理扮演的是客户端的角色，它向服务器发起请求并获得响应。
代理vs网关 严格来说，代理连接的是两个或多个使用相同协议的应用程序，而网关连接的是两个或多个使用不同协议的端点。网关的主要作用是进行协议转换，即使客户端与服务器使用了不同的协议，客户端也可以借助它完成与服务器之间的事务处理。
代理的使用场景 代理服务器可以监视并修改所有经过的HTTP流量，因此可以用它来实现很多有用的功能。例如：
进行内容的过滤、访问控制、路由和转换。 作为防火墙使用。 作为Web缓存使用，维护常用内容的副本，以加快访问速度。 假扮Web服务器，接收发给Web服务器的真实请求并处理。这种代理被称为替代物（surrogate）或反向代理（reverse proxy）。与普通Web服务器不同的是，反向代理可以发起与其它服务器的通信，按需获取请求内容。反向代理还可以用来提高访问慢速Web服务器上公共内容时的速度，通常将这些反向代理称为服务器加速器（server accelerator）。 匿名代理。主动从HTTP报文中删除访问者的身份信息，从而提供高度的私密性和匿名性。 如何将请求导向代理 客户端通常会直接与Web服务器进行通信。为了让代理派上用场，我们需要将到客户端的HTTP流量导向代理，常见的方式有四种：
修改客户端（图a）。很多Web客户端都支持手工和自动的代理配置，可以将客户端配置为使用代理服务器。 修改网络（图b）。网络基础设施可以在客户端不知情的情况下通过一些技术手段将客户端的流量拦截并导入代理，这种代理通常被称为*拦截（intercepting）*代理。 修改DNS的命名空间（图c）。放在Web服务器之前的代理可以直接假扮Web服务器的名字和IP地址，这样，请求就可以直接被发给代理而不是服务器了。要实现这一点，我们可以手动修改DNS列表，也可以采用特殊的动态DNS服务器。 修改Web服务器（图d）。可以将某些Web服务器配置为向客户端发送一个HTTP重定向命令，将客户端的请求重定向到一个代理上去。 客户端代理设置 现在几乎所有的浏览器都允许用户对代理的使用进行配置。配置的方式大概有下面几种:
手工配置。显示地设置使用的代理。 预先配置浏览器。浏览器厂商预先对浏览器进行配置。 代理的自动配置（Proxy Auto-Configuration, PAC）。提供一个指向JavaScript编写的PAC文件的URI，客户端会去获取这个文件并运行，从而决定是否使用以及使用哪个代理服务器。PAC文件的后缀通常是.pac，MIME类型通常是application/x-ns-proxy-autoconfig。 使用Web代理自动发现协议（Web Proxy Autodiscovery Protocol, WPAD）。WPAD协议的算法会使用发现机制逐级上升策略自动地为浏览器发现合适的PAC文件。协议会使用一系列的资源发现技术来判定出适当的PAC文件。 追踪报文 Web请求在从客户端传送到服务器的这个过程中，经过两个或多个代理是非常常见的。随着代理的流行，我们要能够追踪经过代理的报文流，以检测出各种问题，其重要性就跟追踪经过不同交换机和路由器传输的IP数据报流一样。
Via首部 Via首部字段列出了报文途径的每个中间节点（代理或网关）的相关信息，报文每经过一个节点，都必须将这个中间节点添加到Via列表的末尾。例如，下面的报文经过了两个代理：第一个代理为proxy1.com，它实现了HTTP/1.1协议；第二个代理为proxy2.com，它实现了HTTP/1.0：
Via: 1.1 proxy1.com, 1.0 proxy2.com Via首部被用来追踪报文的转发过程、诊断报文路由循环，以及识别整个请求/响应链上所有发送方的协议处理能力。
Via的语法 Via首部包含一个由逗号分隔的路径点（waypoint）。每个路径点都对应一个独立的代理服务器或网关，并且含有与该中间节点的一些信息（比如所采用的协议、节点地址等）。Via首部的语法如下：
Via = &amp;#34;Via&amp;#34; &amp;#34;:&amp;#34; 1#( waypoint ) waypoint = ( received-protocol received-by [ comment ] ) received-protocol = [ protocol-name &amp;#34;/&amp;#34; ] protocol-version received-by = ( host [ &amp;#34;:&amp;#34; port ] ) | pseudonym Via的请求与响应路径 请求和响应报文都会经过代理进行传输。因此，请求和响应报文中都要有Via首部。由于请求和响应通常是在同一条TCP连接上传送的，所以响应报文会在请求报文的路径上反向传输。因此，响应报文的Via首部几乎总是与请求报文的Via首部相反。</description></item><item><title>HTTP：报文结构</title><link>https://zhannicholas.github.io/posts/computer_networks/http/http_messages/</link><pubDate>Sun, 13 Dec 2020 17:15:44 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/http_messages/</guid><description>用于HTTP协议交互的信息被称为HTTP报文（HTTP Messages）。客户端发出的HTTP叫做请求报文（或Requests），服务端发出的报文叫做响应报文（或Responses）。
报文流 作为HTTP应用程序之间发送的数据块，HTTP报文以一些描述了报文内容及含义的文本形式的 元信息（meta-information） 开头，后面跟着可选的数据部分。这些报文在客户端、服务器和代理之间流动，术语流入（inbound）、流出（outbound）、上游（upstream） 和 下游（downstream） 就是用来描述报文的方向的。
Inbound与Outbound HTTP使用术语inbound和outbound来描述事务处理的方向。报文流入源端服务器，处理完成之后又会流出到用户的Agent代理中：
Upstream与Downstream 不管是请求报文还是响应报文，所有的HTTP报文都会向下游（downstream）流动，所有的报文发送者都在接收者的上游（upstream）。报文只会从上游向下游流动，不存在从下游向上游流动的情况：
报文的组成 HTTP报文本身是由多行（用CRLF作换行符）数据构成的字符串文本，包括三个部分：对报文进行描述的起始行（start line）、包含报文属性的首部（headers）和可选的包含数据的主体（body）。例如:
起始行和首部都是由行分隔的ASCII文本，每行都以一个有两个字符组成的行终止符结束。这个行终止符包括一个回车符（Carriage Return, CR, ASCII码为13）和一个换行符（Line Feed, LF, ASCII码为10），CR和LF合起来就是CRLF。需要注意的是，尽管HTTP规范中说明应该用CRLF来表示行终止，但有些老的或不完整的应用程序并不总是同时发送CR和LF，所以应用程序也应该能处理这种情况。
报文的主体是一个可选的数据块。与起始行和首部不同的是，主体中可以包含文本或二进制数据，也可以为空。
报文的语法 所有的HTTP报文都可以分为两类：请求报文（request message）和响应报文（response message）。请求报文请求服务器执行一个操作，而响应报文则会将请求的结果返回给客户端。请求报文和响应报文的基本机构相同，但它们的格式有些许差异。
这是请求报文的格式：
&amp;lt;method&amp;gt; &amp;lt;request-URL&amp;gt; &amp;lt;version&amp;gt; &amp;lt;headers&amp;gt; &amp;lt;entity-body&amp;gt; 这是响应报文的格式（它和请求报文只有起始行不同）：
&amp;lt;version&amp;gt; &amp;lt;status&amp;gt; &amp;lt;reson-phrase&amp;gt; &amp;lt;headers&amp;gt; &amp;lt;entity-body&amp;gt; 下面是对报文格式中各组成部分的一个简短说明：
方法（method）：告知服务器要做什么。 请求URL（request-URL）：指定了所请求资源或URL里面path部分的完整URL。 版本（version）：报文所使用的HTTP版本，格式为：HTTP/&amp;lt;major-version&amp;gt;.&amp;lt;minor-version&amp;gt;。 状态码（status-code）：描述请求过程种发生的情况，每个状态码的第一位数字都对应一类状态。 原因短语（reason-phrase）：这是状态码的可读版本，包含行终止符之前的所有文本。 首部（header）：首部的数量可以为0个、1个或多个，每个首部都包含一个名字，名字后面跟着一个:，然后是一个可选的空格，接着是一个值，最后是一个CRLF。首部总是以一个空行（单个CRLF）结束。 主体（entity-body）：主体部分包含一个由任意数据组成的数据块。这是一个可选的部分，并不是所有的报文都有主体部分，有时，报文只是以一个CRLF结束。 起始行 所有的HTTP报文都以一个起始行作为开始。请求报文的起始行说明了要做什么，而响应报文的起始行则说明了发生了什么。
请求行 请求报文的起始行称为请求行（request line）。请求行包括三部分，即[报文的语法]部分介绍的方法、请求URL和版本，每个部分之间用空格分隔。
响应行 响应报文的起始行称为响应行（response line），它包含了响应报文所使用的HTTP版本、数字状态码和描述操作状态的原因短语。
方法 请求行以方法开始，方法告知服务器要做什么。下面描述了7种常用的HTTP方法：
方法 描述 是否包含body GET 从服务器获取一份文档 否 HEAD 只从服务器获取文档的首部 否 POST 向服务器发送需要处理的数据 是 PUT 将请求的body部分存储在服务器上 是 TRACE 对可能经过代理传送到服务器上的报文进行追踪 否 OPTIONS 决定可以在服务器上执行哪些方法 否 DELETE 从服务器上删除一份文档 否 并不是所有的服务器都实现了以上7种方法。此外，由于HTTP在设计上是易扩展的，一些服务器可能还会实现一些自己的请求方法。</description></item><item><title>HTTP：认证</title><link>https://zhannicholas.github.io/posts/computer_networks/http/http_authentication/</link><pubDate>Sun, 13 Dec 2020 17:14:07 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/http_authentication/</guid><description>Web连接着不计其数的资源，但并不是所有的资源都是可以随意访问的。某些资源只对部分特定的用户开放，为了达到这个目的，需要对用户进行认证（authentication）。通过认证，服务器可以知道用户是谁，进而判定用户可以访问哪些资源。简而言之，认证就是向服务器证明你是谁，而**授权（authorization）**就是服务器授予用户访问特定资源的权限。
HTTP1.1使用的认证方式如下：
BASIC认证（基本认证） DIGEST认证（摘要认证） SSL客户端认证 FormBase认证（表单认证） 此外，还有NTLM、Kerberos、Windows Live ID等认证方式。 HTTP访问认证框架 HTTP提供了一个简单的 质询-响应（challenge-response） 认证机制，服务器可以用它来对客户端请求进行质询，要求用户提供认证信息。下图展示了HTTP的认证模型：
HTTP认证模型由4个步骤组成：
请求（Request）：客户端发送请求。 质询（Challenge）：当客户端请求的资源需要认证时，服务器会以401 Unauthorized状态码拒绝请求，同时在响应报文中添加WWW-Authenticate首部字段。WWW-Authenticate首部字段会对保护区域进行描述并指定认证算法。 授权（Authorization）：客户端重新发起请求，但这次会给请求报文附加一个Authorization首部。Authorization首部说明了认证算法、用户名和密码。 成功（Success）：如果授权成功，服务器就会返回客户端所请求的内容。有些授权算法会在Authentication-Info首部中返回一些与授权会话相关的附加信息。 HTTP允许服务器给不同的资源指定不同的访问权限，这是通过安全域来实现的。Web服务器会将受保护的文档组织成一个安全域（security realm），每个安全域都可以有不同的授权用户。
BASIC认证 BASIC认证早在HTTP/1.0规范中就被提出来了，后来被移到了RFC2617中。现在仍然有一部分网站使用这种传统的认证方式。BASIC认证中会使用WWW-Authenticate和Authorization两个首部，但并不会使用Authentication-Info首部：
质询（服务器发往客户端）：网站的不同部分可能使用不同的密码，Realm是一个字符串，告诉用户该使用哪个账号和密码。首部格式为：WWW-Authenticate: Basic realm=quoted-realm。 响应（客户端发往服务端）：客户端用:将用户名和密码连接起来，然后用Base-64进行编码。首部格式为：Authorization: Basic base64-username-and-password。 BASIC认证的步骤 下面是BASIC认证的一个例子：
BASIC认证的步骤如下：
客户端请求的资源需要BASIC认证的资源。 服务器会随状态码401 Authorization Required返回带WWW-Authenticate首部字段的响应，该字段内包含了认证的方式（BASIC）和请求资源所属安全域（realm=&amp;quot;xxx&amp;quot;）。 客户端向用户询问用户名和密码，然后用:连接二者，再进行Base-64编码处理。编码结果会放在Authorization首部中回送给服务器。 服务器对用户名和密码进行解码，验证它们的正确性。如果验证通过，则返回一条包含请求资源的响应。 代理认证 位于客户端和服务器之间的代理也可以实现认证功能。代理认证的步骤和BASIC认证的身份验证步骤相同，但首部和状态码都有所不同。下表列出了Web服务器和代理在认证中使用的状态码和首部的差异：
Web Server Proxy Server Unauthorized status code: 401 Unauthorized status code: 407 WWW-Authenticate Proxy-Authenticate Authorization Proxy-Authorization Authentication-Info Proxy-Authentication-Info BASIC认证的缺陷 BASIC认证虽然简单便捷，但并不安全。只能用它来防止非恶意用户的无意间访问，或配合SSL等加密技术一起使用。BASIC认证存在一些缺陷：
通过网络发送用户名和密码。虽然用户名和密码经过了Base-64编码，但可以轻松解码。 攻击者可以嗅探到用户名和密码，然后实施重放攻击。 缺乏针对代理或中间人等中间节点的防护措施。 服务器很容易被假冒。 DIGEST认证 BASIC认证虽然简单，但极不安全：用户名和密码是明文传输的，报文也容易被篡改，保证安全的唯一方式就是配合SSL进行BASIC认证。由于BASIC认证无法达到大多数Web网站期望的安全等级，它并不常用。为了弥补BASIC认证的不足，HTTP/1.1引入了DIGEST认证。DIGEST认证同样采用了质询/响应的方式，但不会发送明文密码，因此更加安全。
DIGEST认证步骤 由于DIGEST认证和BASIC认证都采用了HTTP的质询/响应框架，所以DIGEST认证的步骤与BASIC认证的步骤基本相同。下图展示了二者再语法上的差异：
DIGEST认证的步骤如下：
客户端请求受保护的资源。 服务器会随状态码401 Authorization Required返回带WWW-Authenticate首部字段的响应，该字段内包含了认证的方式（DIGEST）、对应的保护域（realm）、临时质询码（nonce，一个随机数）等。realm和nonce这两个字段是必须要有的，客户端需要依靠向服务端回送这两个值进行认证。 客户端再Authorization首部中返回DIGEST认证所必须的信息，包括username、realm、nonce、uri、response的字段信息等。其中realm和nonce就是上一步中从服务器响应中收到的字段。 服务器对客户端提供的信息进行验证。若验证通过，则返回受保护的资源。 参考资料 David Gourley, Brian Totty.</description></item><item><title>HTTP：网关、隧道和中继</title><link>https://zhannicholas.github.io/posts/computer_networks/http/gateway_tunnels_and_relays/</link><pubDate>Sun, 13 Dec 2020 17:07:48 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/gateway_tunnels_and_relays/</guid><description>Web上所有的资源都可以使用HTTP协议，并且其它应用和应用协议也可以利用HTTP来完成它们的任务。开发者可以将HTTP作为一个框架来使用其它协议并进行应用通信，例如：
用网关作为HTTP与其它协议和应用程序之间的接口。 用应用程序接口来实现Web上不同类型资源之间的相互通信。 用隧道在HTTP连接上发送非HTTP流量。 用中继逐跳转发数据。 网关 网关（gateway） 是一种在服务器之间充当中间实体的特殊服务器，通常用来将HTTP流量转换为其它协议流量。网关总是像源服务器一样接收请求，客户端可能并不知道自己在和一个网关通信。
客户端和服务端网关 Web网关在一侧使用HTTP协议，而在另一侧使用另一种协议。
网关可以用一个/分隔的客户端协议和服务端协议进行描述：&amp;lt;client-protocol&amp;gt;/&amp;lt;server-protocol&amp;gt;。例如，一个连接HTTP客户端与FTP服务器的网关就可以被称为HTTP/FTP网关。可以用术语 客户端网关（clent-side gateway） 和 服务端网关（server-side gateway） 来描述对话是在网关的哪一侧进行的：
客户端网关与客户端使用HTTP进行对话，而与服务器使用其它协议（HTTP/*）。 服务端网关与客户端使用其它协议进行对话，而与服务器使用HTTP协议（*/HTTP）。 协议网关 我们可以使用与将流量导向代理相同的方法来将流量导入网关。例如，显式配置浏览器使用网关、对流量进行透明拦截或将网关标记配置为反向代理。
HTTP/*：服务端Web网关 请求流入源服务器时，服务端Web网关会将客户端HTTP请求转换为其它协议。
HTTP/HTTPS：服务端安全网关 一个组织可以通过网关对所有的输入Web请求加密，以提供额外的隐私和安全性保护。客户端可以用普通的HTTP浏览Web内容，但是网关会自动加密用户的对话。
HTTPS/HTTP：客户端安全加速器网关 HTTPS/HTTP网关位于Web服务器之前，通常作为不可见的拦截网关或反向代理使用。它们接收安全的HTTPS流量，对安全流量进行解密，并向Web服务器发送普通的HTTP请求。这些网关通常包含专用的解密硬件，可以高效地解密安全流量，从而降低源服务器的负荷。但是，网关和源服务器之间发送的是未加密的流量，所以需要确保网关和源服务器之间的安全性。
资源网关 应用服务器是网关最常见的形式。应用服务器是服务端网关，它与客户端之间通过HTTP通信，并与服务端的某个应用程序相连。应用服务器可能会将HTTP请求通过**应用编程接口（Application Programming Interface, API）**传递给运行在服务端上的应用程序。
通用网关接口 第一个流行的应用程序网关API就是通用网关接口（Common Gateway Interface, CGI）。CGI是一个标准接口集，Web服务器可以用它来装载程序以处理对特定URL的HTTP请求，收集程序的输出数据并将其放入HTTP响应中回送。
上图展示了服务器与网关应用程序之间的基本交互机制。这个协议（请求、转交、响应）就是CGI模型的基本运行机制。
CGI应用程序是独立于服务器的，因此几乎可以采用任意语言实现。CGI的处理对用户是不可见的。客户端完全不知道服务器和CGI应用程序之间的转接过程，URL中出现字母cgi或可能的?是客户端发现使用了CGI应用程序的唯一线索。
CGI在服务器和众多资源类型之间提供了一个简单的对接方式，可以处理各种需要的转换。此外，他还能很好地保护服务器，防止一些扩展破坏服务器。但是这种分离会造成性能的损失，因为为每个CGI请求都创建一个新进程这一做法的代价是非常昂贵的。
服务器扩展API 大多数流行的服务器都会为开发者提供一个或多个扩展API，这些扩展通常与服务器自身的架构有关系，开发者开一通过这些接口改变服务器的行为或定制实现某些需求。
隧道 隧道（tunnel） 是一种HTTP应用程序，当隧道建立后，它就会在两条连接之间对原始数据进行盲转发。HTTP隧道不会窥探数据，它通常用来在HTTP连接上传输非HTTP数据。利用HTTP隧道，用户可以通过HTTP应用程序访问使用非HTTP协议的应用程序。
隧道的建立 Web隧道是用HTTP的CONNECT方法建立起来的。CONNECT方法请求隧道网关创建一条通向任意目标服务器和端口的TCP连接，并对客户端和服务器之间的后续数据进行盲转发。
上图显示了使用CONNECT方法建立一条到网关的隧道的过程：
客户端发送一条CONNECT请求给隧道网关（图a），请求隧道打开一条TCP连接（这里打开的是一条标准SSL连接）。 建立网关与服务器之间的TCP连接（图b和图c）。 一旦TCP连接建立成功，网关就会发送一条HTTP 200 Connection Established响应给客户端（图d）。 隧道建立完成（图e）。客户端通过HTTP隧道发送的所有数据都会被直接转发给输出TCP连接，服务器发送的所有数据也会通过HTTP隧道转发给客户端。 中继 HTTP中继（relay） 是一个简单的HTTP代理，它没有完全遵循HTTP规范。中继做的事情很简单：建立连接，然后对字节进行盲转发。
参考资料 David Gourley, Brian Totty. HTTP: The Definitive Guide. O&amp;rsquo;Reilly Media, 2002.</description></item><item><title>HTTP：连接管理</title><link>https://zhannicholas.github.io/posts/computer_networks/http/connection_management/</link><pubDate>Sun, 13 Dec 2020 17:05:53 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/connection_management/</guid><description>HTTP连接是HTTP报文传输的关键通道。
TCP连接 TCP/IP是全球计算机及网络设备都在使用的一个分层包交换协议集，几乎所有的HTTP通信都是由TCP/IP承载的。TCP连接时可靠的，它为HTTP提供了一条可靠的比特传输管道，从TCP连接一端传入的字节会在另一端以原有的顺序被正确地传送出来。
TCP会将数据切分为小的数据块发送，这些小的数据块就是IP数据包（IP packets）或IP数据报（IP datagrams）。这个时候，HTTP就位于HTTP over TCP over IP这个协议栈的最顶层，其安全版本HTTPS只是在HTTP和TCP之间插入了一个加密层（称为TLS或SSL）：
HTTP在传送一条报文时，会以流的形式将报文内容通过一条打开的TCP连接按序传输。TCP在收到数据流之后，会先将数据流分割成小数据块（这些数据块被称为段（segments）），然后将段封装在IP数据包中，通过Internet进行传输。所有的这些工作都是由TCP/IP软件来处理的，每个TCP段都由IP数据报承载，从一个IP地址发送到另一个IP地址。每个IP数据包中都包括：
一个IP数据报首部（通常为20字节）。 一个TCP段首部（通常为20字节）。 一个TCP数据块（0或多个字节）。 TCP通过端口号来保持当前打开的TCP连接的正确运行。IP地址帮助我们找到正确的主机，而端口号帮助我们找到该主机上正确的应用程序。一条TCP连接由&amp;lt;source-IP-address, source-port, destination-IP-address, destination-port&amp;gt;四个值唯一标识。
HTTP连接处理 HTTP允许客户端和最终的源端服务器中间存在一个中间实体（intermediary）（代理、缓存等）链。HTTP报文从客户端开始在中间设备间逐跳转发，最终到达源端服务器。或者从源端服务器出发，经过中间设备间的逐跳转发，最终达到客户端。
Connection Header HTTP的Connection首部是一个通用首部，它允许发送方或客户端声明一些只用于某个特定连接的选项，并且这些选项不会（也不能）被其它的连接使用。这些选项就是Connection首部字段中的一个由逗号分隔的连接标签列表。例如：可以用Connection: close来表面发送方希望在响应报文发送之后关闭连接。
Connection首部可以承载3中不同类型的标签：
HTTP首部字段名：列出只与此连接有关的首部。 值close：说明当前的request/response操作完成之后就关闭这条连接。这是HTTP/1.0中的默认值。 任意标签值：描述此连接的非标准选项。 如果连接标签列表中包含了一些HTTP首部字段的名称，那么这些首部字段就包含了一些与连接有关的信息，这些信息是不能被转发出去的。在将HTTP报文被转发出去之前，代理必须删除Connection首部中列出的所有HTTP首部字段。Connection首部是一个逐跳首部，只适用于单各链路并且不应该被顺着链路向下传输。
串行事务处理与短连接 HTTP最早期的模型是短连接（Short-lived connections）。每一个HTTP请求都由它自己独立的连接完成，这意味着每发起一个HTTP请求之前都会进行一次TCP握手。这些连接的生命周期很短：每发起一个请求时都会创建一个新的连接，并在收到响应时立即关闭。
TCP协议握手本身就是很耗时的，所以TCP可以通过保持更多的热连接来适应负载。而短连接破坏了TCP具备的能力，因为新的冷连接降低了其性能。如果每个事务都需要（串行地建立）一条新的连接，那么TCP的连接时延和慢启动时延就会叠加起来。
短连接是HTTP/1.0的默认模型（如果没有指定Connection头，或它的值被设置为close）。而在HTTP/1.1中，只有当Connection被设为为close时才会用到短连接模型。
短连接对TCP性能有先天的限制：每打开一个TCP连接都是相当耗费资源的操作。为了解决短连接模型的低效率问题，出现了几种新的模型：
并行连接（Parallel connections）：通过多条TCP连接发起并发的HTTP请求。 持久连接（Persistent connections）：重用TCP连接，以消除打开及关闭TCP连接时的时延。 管道化连接（Pipelined connections）：通过共享的TCP连接发起并发的HTTP请求。 复用连接（Multiplexed connections）：交替传送请求和响应报文。 并行连接 HTTP允许客户端打开多条连接，并行地执行多个HTTP事务，每个事务都有自己的TCP连接。
例如，当一个网页里面包含多个组件的时候，如果并行连接能够克服单条连接的空载时间和宽带限制，网页的加载速度就会有所提高。时延可以重叠起来，如果单条连接没有充分利用带宽，空闲的带宽可以用来加载其它组件。
需要注意的是：并行连接可能会更快，但不一定总是更快。当一个较慢的客户端连接到较快的服务器上时，慢客户端的带宽可能很快被耗尽，接着就是带宽资源的竞争，这可能并不会带来性能的提升。因为，打开大量连接会消耗很多的内存资源，从而引发自身的性能问题。
很多浏览器都使用了并行连接，但它们一般都会将并行连接的总数限制在一个较小的值，而服务器可以随意关闭来自特定客户端的过量连接。
持久连接 Web客户端经常会打开到同一个站点的连接，并且可能会在将来的一段时间内对该站点发起更多的请求，这种性质就是站点的局部性（site locality）。
因此，HTTP/1.1（以及HTTP/1.0的各种增强版本）允许HTTP设备在事务处理结束之后保持TCP连接的打开状态，以便将来的HTTP请求可以重用现有的连接。在事务结束之后仍然保持在打开状态的TCP连接被称为持久连接（persistent connections）。非持久连接会在每个事务结束之后关闭，而持久连接会在不同事务之间保持打开状态，直到客户端或服务器决定将其关闭位置。
重用已经对目标服务器打开的空闲持久连接，客户端就可以避开建立连接阶段的高昂开销。此外，已经打开的连接可以避免慢启动的拥塞适应阶段，以便更快速地进行数据的传输。
持久连接有两种类型：
比较老的HTTP/1.0+中的keep-alive连接。 HTTP/1.1中的persistent连接。 并行连接 vs 持久连接 并行连接虽然可能比较快，但并行连接也有一些缺点：
每个事务都会打开/关闭一条新的连接，这会耗费时间和带宽。 由于TCP的慢启动特性，每条新连接的实际性能会有所降低。 可打开的并行连接的最大数量实际上是有限的。 持久连接有一些比并行连接更好的地方。持久连接可以有效的降低时延和建立连接的开销，还可以很方便地控制打开连接的数量。但是，一直打开的大量空闲连接会带来新的问题，它们会消耗客户端与服务器的资源。因此，管理持久连接时要特别仔细。
HTTP/1.0+中的Keep-Alive连接 和短连接相比，持久连接节省了打开/关闭连接和TCP慢启动阶段的开销。
在当前的HTTP/1.1规范中，keep-alive已经被弃用了。但是，keep-alive握手操作仍然在浏览器与服务器之间广泛使用。
实现了HTTP/1.0 keep-alive连接的客户端可以通过在请求头里面包含Connection: Keep-Alive来告诉服务器它希望连接保持打开状态。若服务器也愿意为下一条请求而保持连接的打开状态，它也会将Connection: Keep-Alive放入响应头。如果响应报文中没有Connection: Keep-Alive，那么客户端就会认为服务器不支持keep-alive并且服务器会在发回响应报文之后关闭连接。</description></item><item><title>HTTP：客户端身份识别与Cookie</title><link>https://zhannicholas.github.io/posts/computer_networks/http/client_certification_and_cookies/</link><pubDate>Sun, 13 Dec 2020 16:59:47 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/client_certification_and_cookies/</guid><description>HTTP 最初是一个匿名、无状态的请求/响应协议。服务器接收客户端请求，处理并回送响应，Web 服务器几乎没有什么信息可以用来判断请求来自于哪个用户。通常情况下，Web 服务器可能同时和上千个客户端进行通信。现代的Web站点希望能够为不同用户提供个性化体验，因此服务器需要通过某种方式识别出当前对话的用户。常见的用户识别机制有：
使用承载有用户身份信息的 HTTP 首部。 追踪客户端的 IP 地址。 通过登录认证来识别用户。 使用 Fat URL，在 URL 中嵌入识别信息。 使用 cookie 。 承载有用户信息的HTTP首部 常见的用来承载用户信息的HTTP首部有：
首部名称 首部类型 描述 From Request 用户的Email地址 User-Agent Request 用户的浏览器 Referer Request 用户是从这个页面上面的链接跳转过来的 Authorization Request 用户名和密码 Client-ip Extension (Request) 客户端IP地址 X-Forward-For Extension (Request) 客户端IP地址 Cookie Extension (Request) 服务端生成的ID标签 From 首部包含了用户的 E-mail 地址，这在理想情况下可以用来识别用户。但某些服务器可能会收集这些 E-mail 地址，用于散发垃圾邮件，所以很少有浏览器会发送 From 首部。From 首部一般是由向机器人或蜘蛛这样的自动化程序发送的。
User-Agent 可以将用户浏览器的相关信息发送给服务器。这些信息包括程序的名称、版本，甚至操作系统的相关信息等。例如：
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.</description></item><item><title>HTTP：缓存</title><link>https://zhannicholas.github.io/posts/computer_networks/http/caching/</link><pubDate>Sun, 13 Dec 2020 16:41:19 +0800</pubDate><guid>https://zhannicholas.github.io/posts/computer_networks/http/caching/</guid><description>Web缓存指的是一些可以自动保存常用文档副本的HTTP设备。当Web请求经过缓存时，如果缓存设备本地存在一个可用的“已缓存”副本，就不需要再去**源服务器（origin server, 即持有资源实体的服务器）**获取这个文档了，直接将缓存设备本地存储中的文档副本返回给客户端即可。缓存具有不少优点：
减少冗余的数据传输，从而节省网络费用。 缓解网络瓶颈问题。有了缓存之后，可以更快地加载页面而不需要更多的带宽。 降低对源服务器的要求。服务器不仅可以更快地响应，还能避免过载的出现。 降低距离时延。因为从较远的地方加载页面会更慢。 缓存命中与不命中 缓存是很有用的，但一个缓存也不可能存储下世界上所有文档的副本。
当请求到达缓存时，若缓存中存在被请求内容的副本（副本应该是有效的），则可以直接将副本返回给客户端，这种情况被称为缓存命中（cache hit）。否则，缓存中没有可用副本，请求会被转发给源服务器，这种情况被称为缓存不命中（cache miss）。源服务器上的内容可能会发生变化，缓存需要不时地对其进行检测，看看它们保存的副本是否仍然是服务器上的最新内容，这些*新鲜度检测（freshness checks）*就被称为HTTP再验证（HTTP revalidation）。
再验证 HTTP定义了一些特殊的请求，它们可以不从服务器获取整个对象，并快速检测出内容是否依然是新鲜的。缓存可以在任意时刻，以任意频率对副本进行再验证。由于网络带宽非常珍贵，大部分缓存只有在客户端发起请求并且副本旧得足以需要检测时，才会对副本进行再验证。
缓存在对副本进行再验证时，会向源服务器发送一个小的再验证请求。如果内容没有发生变化，服务器就会以 304 Not Modified 进行响应。只要缓存确认了副本仍然是有效的，它机会再次将副本标记为新鲜的并将副本提供给客户端，这被称为再验证命中（revalidation hit）或缓慢命中（slow hit）。因为这种方式需要与源服务器进行核对，所以比单纯的缓存命中要慢，但它没有从服务器获取对象数据，所以比缓存不命中要快一些。
HTTP提供了一些再验证缓存对象的工具，其中最常用的就是 If-Modified-Since 首部。当它被添加到GET请求中时，它告诉服务器只有当对象的副本被缓存并且对象已经被修改后，才发送对象。当服务器收到GET If-Modified-Since请求时，可能处于三种状态:
服务器内容未修改（再验证命中）。服务器向客户端发送 304 Not Modified 作为响应。 服务器内容已修改但未删除。这是服务器对象与缓存副本已经不同了，服务器会向客户端发送一条带有完整内容的普通 200 OK 作为响应。 服务器对象已被删除。这个时候服务器会回送一个 404 Not Found 响应，缓存收到后会将对应的副本删除。 缓存的处理步骤 Web缓存对一条HTTP GET报文的处理过程包括以下7个步骤：
接收——缓存从网络中读取抵达的请求报文。 解析——缓存对报文进行解析，提取出URL和各种首部。 查询——缓存查询本地是否存在可用副本，如果没有就从服务器获取一份并保存在本地。 新鲜度检测——缓存查看已缓存的副本是否足够新鲜，如果不是，就询问服务器该内容是否有更新。 创建响应——缓存使用新的首部和已缓存的主体来构建一条响应报文。 发送——缓存将响应报文发送给客户端。 日志——缓存向日志文件中新增一个描述这个事务的条目（可选）。 下面的流程图展示了缓存是如何处理GET请求的：
保持副本的新鲜 HTTP提供了一些机制用来保持已缓存数据与服务器数据之间的一致性。这些机制被称为文档过期（document expiration）和服务器再验证（server revalidation）。
文档过期 通过HTTP的 Cache-Control 和 Expires 首部，源服务器可以为每个文档附加一个“过期时间”，从而说明在多长时间内可以认为这些内容是新鲜的。
在缓存文档过期之前，除非客户端请求中包含阻止提供已缓存或未验证资源的首部，缓存可以不与服务器联系并任意使用这些副本。一旦文档过期，缓存就必须与服务器进行核对。
服务器用HTTP/1.0+的 Expires 首部或HTTP/1.1的 Cache-Control: max-age 首部来指定过期时间。二者所做的事情本质上是一样的，区别在于：前者使用绝对时间，后者使用相对时间。
服务器再验证 已缓存文档过期了并不意味着它与源服务器上目前处于活跃状态的文档有本质区别，这只是意味着到了核对时间了，这种情况就是服务器再验证，缓存需要询问源服务器文档是否发生了变化：</description></item></channel></rss>